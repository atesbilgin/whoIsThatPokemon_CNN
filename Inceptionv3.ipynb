{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x1600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6541 images belonging to 150 classes.\n",
      "Found 289 images belonging to 57 classes.\n",
      "WARNING:tensorflow:From <ipython-input-1-2ba48bd2e707>:134: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1 steps, validate for 5 steps\n",
      "Epoch 1/5\n",
      "1/1 - 29s - loss: 0.7631 - acc: 0.6973 - val_loss: 1.5793 - val_acc: 0.9825\n",
      "Epoch 2/5\n",
      "1/1 - 12s - loss: 0.2241 - acc: 0.9933 - val_loss: 1.3911 - val_acc: 0.9825\n",
      "Epoch 3/5\n",
      "1/1 - 13s - loss: 0.1984 - acc: 0.9933 - val_loss: 1.2551 - val_acc: 0.9825\n",
      "Epoch 4/5\n",
      "1/1 - 12s - loss: 0.1847 - acc: 0.9933 - val_loss: 1.1375 - val_acc: 0.9825\n",
      "Epoch 5/5\n",
      "1/1 - 13s - loss: 0.1683 - acc: 0.9933 - val_loss: 1.0267 - val_acc: 0.9825\n"
     ]
    }
   ],
   "source": [
    "# -*- inception deneme -*-\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "\n",
    "base_dir = 'D:\\pokemon small dataset\\inceptiondeneme'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "# Directory with our training cat pictures\n",
    "train_alakazam = os.path.join(train_dir, 'Alakazam')\n",
    "train_aerodactyl = os.path.join(train_dir, 'Aerodactyl')\n",
    "train_arcanine = os.path.join(train_dir, 'Arcanine')\n",
    "train_goldeen = os.path.join(train_dir, 'Goldeen')\n",
    "\n",
    "validation_alakazam = os.path.join(validation_dir, 'Alakazam')\n",
    "validation_aerodactyl = os.path.join(validation_dir, 'Aerodactyl')\n",
    "validation_arcanine = os.path.join(validation_dir, 'Arcanine')\n",
    "validation_goldeen = os.path.join(validation_dir, 'Goldeen')\n",
    "\n",
    "\n",
    "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
    "import matplotlib.image as mpimg\n",
    "nrows = 4\n",
    "ncols = 4\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(ncols*4, nrows*4)\n",
    "pic_index = 100\n",
    "train_alakazam_fnames = os.listdir( train_alakazam )\n",
    "train_aerodactyl_fnames = os.listdir( train_aerodactyl )\n",
    "train_arcanine_fnames = os.listdir( train_arcanine )\n",
    "train_goldeen_fnames = os.listdir( train_goldeen )\n",
    "\n",
    "\n",
    "next_alakazam_pix = [os.path.join(train_alakazam, fname) \n",
    "                for fname in train_alakazam_fnames[ pic_index-8:pic_index] \n",
    "               ]\n",
    "\n",
    "next_aerodactyl_pix = [os.path.join(train_aerodactyl, fname) \n",
    "                for fname in train_aerodactyl_fnames[ pic_index-8:pic_index] \n",
    "               ]\n",
    "\n",
    "next_arcanine_pix = [os.path.join(train_arcanine, fname) \n",
    "                for fname in train_arcanine_fnames[ pic_index-8:pic_index] \n",
    "               ]\n",
    "\n",
    "next_goldeen_pix = [os.path.join(train_goldeen, fname) \n",
    "                for fname in train_goldeen_fnames[ pic_index-8:pic_index] \n",
    "               ]\n",
    "\n",
    "\n",
    "\n",
    "for i, img_path in enumerate(next_alakazam_pix+next_aerodactyl_pix+next_arcanine_pix+next_goldeen_pix):\n",
    "  # Set up subplot; subplot indices start at 1\n",
    "  sp = plt.subplot(nrows, ncols, i + 1)\n",
    "  sp.axis('Off') # Don't show axes (or gridlines)\n",
    "\n",
    "  img = mpimg.imread(img_path)\n",
    "  plt.imshow(img)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Import the inception model  \n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), # Shape of our images\n",
    "                                include_top = False, # Leave out the last fully connected layer\n",
    "                                weights = 'imagenet')\n",
    "\n",
    "for layer in pre_trained_model.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(pre_trained_model.output)\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "# Add a dropout rate of 0.2\n",
    "x = layers.Dropout(0.2)(x)                  \n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
    "\n",
    "model = Model( pre_trained_model.input, x) \n",
    "\n",
    "model.compile(optimizer = RMSprop(lr=0.0001), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['acc'])\n",
    "\n",
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
    "                                   rotation_range = 40,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,batch_size = 20,class_mode = 'categorical', target_size = (150, 150))     \n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
    "                                                          batch_size  = 20,\n",
    "                                                          class_mode  = 'categorical', \n",
    "                                                          target_size = (150, 150))\n",
    "\n",
    "def myCallback():\n",
    "    return 0\n",
    "\n",
    "callbacks = myCallback()\n",
    "history = model.fit_generator(\n",
    "            train_generator,\n",
    "            validation_data = validation_generator,\n",
    "            steps_per_epoch = 1,\n",
    "            epochs = 5,\n",
    "            validation_steps = 5,\n",
    "            verbose = 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
